How should we design systems for analyzing and exploring the high-throughput
datasets that facilitate sharing, reuse, and reproducibility? This dissertation
shows that in many cases the solution is to decompose the applications into
small entities that communicate using open protocols. This enables the
development of unified systems for reproducible exploration and analysis. 

While high-throughput datasets and computing systems will undoubtedly evolve, we
hope that the \gls{sme} approach proposed here can offer a new perspective on
developing applications for exploring and analyzing biological data. We hope
that our approach can steer the tradition away from developing large monolithic
bioinformatics applications, over to applications composed of diverse systems.
We believe that this approach can help the community develop new tools to meet
the needs of the faster growing biological datasets. 

In Chapter \ref{biodata} we show that we can store the biological data and
analysis code from a complex epidemiological study in a shareable software
package. We show how we explicitly track versions of code and data, and how we
can generate reproducible data analysis reports for the processed datasets. We
also show its usefulness as a basis for standardizing the preprocessing of its
biological datasets. In chapter \ref{interactive} we show how we can build
interactive data exploration applications that interface with these software
packages through a microservice architecture. We have implemented this approach
through the microservices in \emph{Kvik}. We show that this architecture style
is suitable for building such applications, and have used it to develop the
\emph{Kvik Pathways} and \emph{MIxT} web applications.  In chapter
\ref{pipeline} use the same approach to develop biological data analysis
pipelines, implemented in \texttt{walrus} using a composition of different
tools. To ensure reproducible results, we supplement the processing with data
versioning to track provenance of the data through the pipeline and across
pipeline versions. 

Combined, these systems demonstrate the applicability of our approach across a
range of different use cases. 

In the rest of this chapter we summarize some lessons learned during this
work. We then discuss the work in the context of research and in the clinic,
before we propose areas for future work. 


\section{Lessons Learned}
Through the design of the \gls{sme} approach to analysis and exploration, as
well as the different implementations we have encountered challenges and
learnt lessons.  

\textbf{There is no single solution programming language or system.} In the
field of bioinformatics there has been tremendous efforts to develop analysis
tools that keep up with the data generation. This has led to systems being
written in a plethora of different languages, and deployed on top of different
systems.  This is one of the largest motivations behind our \gls{sme} approach
together with software containers. We want to take advantage of the existing
tools without having to develop an entire application in the same language or
system.

\textbf{Researchers in systems epidemiology are not software engineers.} When
designing a new approach to store and analyze research datasets, it is important
to remember that its users have limited software engineering backgrounds.
Especially when the implementation is based on complex systems such as
\texttt{git}, the learning curve for the system is steep and require training of
its users. In our project we have organized workshops in both R and git to get
the researchers in the \gls{nowac} study comfortable with these systems. 

\textbf{Simplicity is key.} When proposing a new approach for either managing
datasets, writing data exploration applications, or developing analysis
pipelines, it is not possible to overstate the importance of the simplicity of
the solution. Through our experiences we have tried different 


% \textbf{Define the data storage and analysis requirements before collecting
% data.} 

% \section{Broader Impact}
% balkanized 
% clinica

\section{Future Work}
As we have described in all previous chapters there are some limitations to our
approach and its implementations. To summarize these, the main areas for
improvement are: 

\begin{itemize} 

\item \textbf{Versioning of datasets:} \texttt{git} was not designed to version
large binary files, such as biological datasets, and it does not provide the
required performance or scalability to version the large biological data. It is 


% Rob Pike said this: 
% Measure. Don't tune for speed until you've measured, and even then don't
% unless one part of the code overwhelms the rest.
% http://www.catb.org/~esr/writings/taoup/html/ch01s06.html
\item \textbf{Thorough evaluation:} while we have shown that the \gls{sme}
approach can be used to develop systems for managing research data, developing
interactive 

\item \textbf{Refactoring and test coverage:} while we provide fully implemented
solutions for data storage, interactive applications, and data analysis
pipelines, they all have areas of improvement with regards to performance,
scalability, and robustness. More active developers as well as application areas
will lead to the improvement of the underlying source code. 

\item \textbf{Distributed execution:} while \texttt{walrus} orchestrate
execution of Docker containers, we do not support the execution of these on
multiple compute nodes. Distributing the computation on multiple machines will
have positive impact on the execution time if we can share the data across the
machines successfully. We would also like to evaluate the possibility of using
Kubernetes to orchestrate the execution of an analysis pipeline. 


\item \textbf{Wide adoption of a pipeline description format:} we are not the
first to propose a new computing standard.\footnote{\url{xkcd.com/927}} We found
that the current standards were either too verbose, or did not require the use
of software containers, which we believe are instrumental to make the pipeline
reproducible. However, we recognize the need for oen 

\end{itemize} 

We hope to refine and continue development on our \gls{sme} approach to address
these challenges, and that we can inspire a more unified development community
in bioinformatics. 
