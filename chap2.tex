From the discovery of the \gls{dna} structure by Watson and Crick in
1953\cite{watson1953molecular} to the sequencing of the human genome in 2001
\cite{venter2001sequence,international2001initial} and the massively parallel
sequencing platforms in the later years[6], the scientific advances have been
tremendous. Today, single week-long sequencing runs can produce as much data as
did entire genome centers just years ago.\cite{kahn2011future}  These
technologies allow researchers to collect data faster, cheaper and more
efficient, now making it possible to collect the entire genome from a patient in
less than a days work.

In this chapter we give a background in the different aspects of analyzing and
exploring biological datasets. We use the \gls{nowac} study as an example and
highlight the necessary processing steps from data generation and to
interpretation of results. In addition we describe the traditional data analysis
and management, and propose a novel approach for organizing, sharing, and
collaborating on research data and analyses. 

\section{High-Throughput Datasets in Research and Medicine} 
\gls{dna} sequencing is the process of determining the order of nucleotides
within a strand of \gls{dna}. 

Precision medicine uses patient-specific molecular information to diagnose and
categorize disease to tailor treatment to improve health
outcome.\cite{national2011toward} Important research goal in precision medicine
are to learn about the variability of the molecular characteristics of
individual tumors, their relationship to outcome, and to improve diagnosis and
therapy.\cite{tannock2016limits} International cancer institutions are therefore
offering dedicated personalized medicine programs, but while the data collection
and analysis technology is emerging, there are still unsolved problems to enable
reproducible analyses in clinical settings. For cancer, high throughput
sequencing is the main technology to facilitate personalized diagnosis and
treatment since it enables collecting high quality genomic data from patients
at a low cost. 

\subsection{Sequencing} 
TODO: What is sequencing data, how is it obtained and what does it look like. 
\subsection{Gene expression} 
TODO: What is gene expression, how is it obtained, and what does it look like.

\section{Norwegian Women and Cancer (\gls{nowac})} 
The \gls{nowac} study is a prospective population-based cohort that tracks 34\%
of all Norwegian women born between 1943â€“57.\cite{lund2007cohort} We started the
data collection in \gls{nowac} in 1991 with questionnaires to cover, among
others, the use of oral contraceptives and hormonal replacement therapy,
reproductive history, smoking, physical activity, breast cancer, and breast
cancer in the family.  We also integrate the Norwegian Cancer Registry, the
register of the National Mammographic Screening Program, and the register of
death certificates in Statistics Norway.  In addition to the questionnaire data,
the \gls{nowac} biobank now contain blood samples from 50 000 women, as well as
tumor tissue samples. From the biological samples we have generated gene
expression, miRNA, methylation, and RNA sequencing datasets. 

From the \gls{nowac} cohort we have have published a number of research papers
that investigate the questionnaire data\cite{find-some-papers}. We have also
used the gene expression datasets to explore ... and interactions between the
tumor and the blood systemic response of breast cancer
patients.\cite{dumeaux2017interactions} While we have studied interesting
patterns and questions, there are still unexplored areas in the available
datasets.

\subsection{Data Management} 
In the \gls{nowac} study questionnaire data is stored on an in-house dedicated
database backed up to an independent storage node. The database is maintained by
a handful of personnel which are also responsible for extracting data for
researchers and projects. This is typically done through SAS scripts that
selects the applicable variables and samples, and optionally generate computed
variables such as smoking status from the questionnaire data. There is no
systematic version control of the datasets or processing scripts. 

In addition to the questionnaire data, the \gls{nowac} study also integrates
with registries which are updated regularly. The datasets from the different
registries are typically delivered as \gls{csv} files which are then processed
into a standardized format. Since the \gls{nowac} study is a prospective cohort
women are expected to get cancer and move from the list of controls into the
list of cases. 

In the \gls{nowac} study we have used third-party sources to process and analyze
biological samples. The resulting datasets were then stored on a local
compute-node and made available to researchers on demand. Because of the nature
of the biological datasets, many of these require extensive pre-processing
before they are analysis-ready. 

There are multiple drawbacks to managing the research datasets using the
traditional approach detailed above. First, it is a difficult task to retrace
original data when the data extraction scripts are not versioned and kept track
of in a shared repository. Second, while datasets are backed up, there is no
information about changes between dataset versions. For example, samples may be
removed and there is no record of these changes. 

\subsection{Data Analysis} 
Traditionally, researchers had to send an application to get data exported from
the database by an engineer. The downstream analysis of questionnaire data was
typically done in SAS on local computers.  Traditionally researchers have used
e-mail to communicate and share data analysis scripts, and there has not been a
central hub to share scripts or data. Because of the many packages in
Bioconductor\footnote{bioconductor.org} we have used R to analyse the different
gene expression datasets in the projcet. However like with SAS the researchers
have typically shared scripts through e-mail and there has not been a tradition
to version control the analysis scripts. Results from the analyses are often
communicated through research papers subsequently. 

There are several drawbacks to this approach. First, there are obvious drawbacks
of not version controlling analysis scripts 
Second, sharing analysis scripts through e-mail and not centralized repositories
makes it difficult to share code especially in research groups with researcher
turnover. 
Third, using proprietary software
such as SAS makes it difficult for anyone without the necessary licences to
revisit the analyses. Last, separating the reporting of the results from the
actual data analysis leaves room for human errors when generating tables or
plots. 



\subsection{Requirement Analysis} 
To enable more researchers to benefit from the unique datasets in \gls{nowac} we
wanted to improve the way researchers access data as well as how they share
their analyses. By improving access and how the researchers share analyses we
are indirectly improving reproducibility in the project. 

Before developing an approach to standardize data management and analysis in the
\gls{nowac} study we performed a requirement analysis and determined the
following requirements for such systems: 

\begin{itemize} 
    \item It provides a single location for storing datasets and analysis code.
    \item it provides documentation for the datasets, how they are processed,
    and other useful information for downstream analyses. 
    \item It enables the standardization of pre-processing steps required to
    analyze biological datasets. 
\end{itemize}

From these requirements we designed and implemented i) a software package in the
R programming language that contain all datasets, their documentation, and
useful analysis functions to work with the data, and ii) a \gls{gui} for
to perform the necessary pre-processing steps before delivering
datasets to researchers, and iii) 
best practices for researchers that want to work with datasets from the
\gls{nowac} cohort. 
In the next sections we describe the software packages and best practices. 


\section{Modernizing Data Management and Analysis} 
The first step in modernizing the data management and analysis in the
\gls{nowac} study was to identify the neccessary 


\subsection{Data management} 

\subsection{Data processing} 

\subsection{Best Practices} 



\section{Preprocessing} 

\section{Analysis Pipelines}
% Watchdog:
% https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-018-2107-4
% maybe this one
% http://gopherdata.io/post/more_go_based_workflow_tools_in_bioinformatics/

\section{Interactive Applications} 
