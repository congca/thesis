% observation
There is a rapid growth in the number of available biological datasets due to
the decreaseing cost of data collection. This brings opportunities to gain novel
insights to the underlying biological mechanisms in the development and
progression of diseases such as cancer, possibly leading to the development of
novel diagnostic tests and drugs for treatment.  The wide range of different
biological datasets has led to the development of a wealth of software packages
and systems to explore and analyze these datasets.  However, there are few tools
toat are designed with the full analysis pipeline in mind, from raw data into
interpretable results. While the tools are used to provide novel insights in
diseases, there is little emphasis on reporting and sharing information about
tool versions, input parameters, and other information that can help others use
the same known methods on their own datasets.  This leads to unneccesary
difficilties to reuse known methods, and difficulties in reproducing analyses,
which leads to longer analysis times and unrealized potential for scientific
insights.

% challenge
There are several computational challenges challenges for researchers to analyze
and explore biological datasets. These challenges are common for large datasets
such as high-throughput sequencing data that require long-running, deep analysis
pipelines, as well as smaller datasets, such as microarray data, that require
complex, but short-running analysis pipelines. The first is the time and
knowledge required to find and set up the necessary analysis tools to start
analyzing a modern biological dataset. The second is ensuring the correct input
parameters, tool versions, database versions, and dataset versions when
analyzing, and reporting analysis results to enable reproducible science. A
third challenge is efficiently exploring the results of the analyses
interactively. This includes developing tools that can efficiently visualize the
heterogeneous datsets and integrate them with known biology from databases to
provide necessary information for interpreting the results.  The final challenge
is reusing the analysis pipelines and exploration tools with new datasets,
methods, and research questions. 


As a result, there are a wealth of specialized approaches and systems to enable
analysis of the complex biological data. To develop deep analysis pipelines in
bioinformatics, Galaxy\cite{galaxy} has for a long time provided a simple
interface to set up and execute analysis pipelines for genomic datasets.
However, the Galaxy system is less effective for explorative and flexible
analyses where it is necessary to try out different tools with different
configurations.\cite{spjuth2015experiences} New initiatives such as the
\gls{cwl} provide users a standardized way of describing and sharing an analysis
pipeline, and has multiple implementations such as the reference implementation
cwl\_runner,\footnote{\url{github.com/common-workflow-language/cwltool}}
Arvados,\cite{arvados} Rabix,\cite{rabix} Toil,\cite{toil} Galaxy,\cite{galaxy}
and AWE.\cite{awe}
While these systems provide a viable option for batch-processing of
large biological datasets, researchers with smaller datasets at hand, can
analyze and explore them through interactive languages and interpreters such as
Python or the  R programming language.  Through the package repository
Bioconductor, there are a wide range of R packages to analyze biological
datasets. These include tools for both analyzing and visualizing the datasets.
For users with little or no programming experience it is possible to access and
explore datasets thorough applications using the Shiny or OpenCPU frameworks.
These let developers write applications in the R programming language, and users
can access and explore the data through web applications. Standalone systems
such as Cytoscape provide a specialized software platform to visualize and
explore complex biological datasets.\cite{cytoscape} 
Generalized systems for analyze a wide range of big datasets are now starting to
get attention in bioinformatics. An example of one of these is Pachyderm, a
system for deploying and managing multi-stage, lagnuage-agnostic data
pipelines.\cite{pachyderm} In addition to tracking pipeline configrations,
it also provides full provenance for the data.
Another example is Aparche Spark, an analytics engine for large-scale data
processing.\cite{spark}. Both of these provide useful abstractions for
reproducible analyses of large-scale datasets, but they have yet to see
wide-spread adpotion in Bioinformatics.  
With the addition of new datasets and methods every year, it seems that analysis
of biological data requires a wide array of different tools and systems.

% our solution
This dissertation argues that, instead, we can design a unified approach that
integrates disperate systems and data into fully reproducible biological data
analysis frameworks.  In particular, we show how software container technologies
together with well-defined interfaces, configurations, and orchestration provide
the necessary foundation to build reproducible environments for any analysis
pipeline, as well as a suitable environment build an entire data exploration
application. 

The resulting approach as several key advantages when implementing systems to
analyze and explore biological data:
\begin{itemize} 
    \item It enables reproducible research by packaging applications
        and tools within containerized environments. This enables sharing of
        tools and simplifies the tedious task of installing a specific tool. 

    \item It simplifies the sharing of analysis pielines and workflows across
        different research teams and systems. This shortens the
        time-to-interpretation for biological datasets. 

    \item It enables applications to use tools written in any programming
        language, using open standards to communicate between tools and systems.
        This allows for exploration tools to interface with both statistical
        analyses and biological databases. % evt. kutte siste setning...
        
    \item It facilitates the development of flexible and configurable systems by
        separating appliications and tools into small composable parts. This
        allows developers to reuse parts of a system to fit new methods and
        datasets. 
\end{itemize} 

From collaboration with researchers in systems epidemiology and precision
medicine we were asked to develop a set of applications and systems that could
enable them to analyze and explore their datasets. From these systems we
extraplolated a set of general design principles to form a unified approach. 
We implement our approach thorugh a series of applications and tools built on
top of a stack of open source systems with software containers as the common
foundation.  We evaluate the approach through these systems using real datasets
and show its viability. 

From a longer-term perspective we discuss the general patterns for implementing
modern data analysis systems for use in precision medicine and dicuss why our
approach is a suitable option. As more datasets are produced every year,
research will depend on systems being easy to pick up, and provide the necessary
functionality to reproduce and share the analysis pipelines. 

\emph{Thesis statement}:
A unified development model based on software container infrastructure can
efficiently provide reproducible and easy to use environments to develop
applications for exploring and analyzing biological datasets. 

\section{Problems with Data Analysis and Exploration in Bioinformatics}
Today there is a move towards using more sophisticated approaches to analyze
biological datasets through workflow and pipeline mangers such as
Galaxy\cite{galaxy} and the \gls{cwl}\cite{cwl}. These simplify setting up the
analysis pipeline pipeline, maintaining, and updating it. However, these tools
still have their limitations and shell scripts are still the de facto standard
building analysis pipelines in bioinformatics. 
For exploring biological data there are a range of tools, such as
Cytoscape\cite{cytoscape} and Circos\cite{circos},
% more tools? other tools? 
that support importing an already-analyzed dataset to visualize and browse the
data. 

Although there are efforts to develop tools to help researchers explore and
analyze biological datasets, they current tools have several drawbacks:

\begin{enumerate}
    \item \textbf{Reusability:} Data exploration tools are often
        developed as a single specialized application, making it difficult to
        reuse parts of the application for other analyses or datasets. This
        leads to duplicate development effort and abandoned projects. 
    \item \textbf{Decoupling:} Data exploration tools are often decoupled from
        the statistical analyses, making it a difficult exercise to document and
        retrace the analyses behind the results. 
    \item \textbf{Complexity:} 
        Analyses that start as a simple script quickly become more difficult to
        maintain and develop as developers add new functionality to the
        analyses.
    \item \textbf{Reproducibility:} While there are tools for analyzing most
        data types today, there is little or no effort to fully document the
        entire pipeline from raw data to interpretable results. This includes
        tool versions, parameters, data, and databases. This makes analysis
        results difficult to reproduce. 
\end{enumerate} 

% vet ikke helt as... 
Because of these drawbacks, an approach for reproducible data analysis and
exploration would have significant benefits in usability and 
% LAB: transparency er nytt
transparency of
complex analyses of biological data.

\section{The X Model/approach/etc.} 
% The Solution (?). Talk about the ideas behind building apps on top of
% containers  
% LAB: & how limiations are solved
    
\textbf{Deep analysis pipelines}. 
Analysis of high-throughput sequencing datasets requires deep analysis pipelines
with a large number of steps that transform raw data into interpretable
results\cite{diao2015building}. We used our approach to implement walrus, a tool
that lets users create and run analysis pipelines. In addition, it tracks full
provenance of the input, intermediate, and output data, as well as tool
parameters. With \emph{walrus} we have successfully built analysis pipelines to
detect somatic mutations in breast cancer patients. 

\textbf{Interactive exploration}. Analysis pipelines and workflows typically
require researchers to browse and explore the final output. In addition it may
be useful to further explore results by modifying analysis parameters to execute
new analyses.  To develop data exploration applications that interface with the
underlying statistical analyses we have built \emph{Kvik}. Kvik allows
applications written in any modern programming language to interface with the
wealth of bioinformatics packages in the R programming language, as well as
information available through online databases. We have used Kvik to develop the
\gls{mixt} system for exploring and comparing transcriptional profiles from
blood and tumor samples in breast cancer patients. 


\section{Systems Implemented with the X Model/approach/etc.} 
% LAB: walrus, Kvik, etc syens jeg hører til i "The solution". Her ville jeg
% heller beskrvet applications. Dvs hva er laget? hva slags problem løser den?
% hva er det brukt til?
% Dvs:
% 1. NOWAC package (men merk at data managment challenges/limitations ikke er
% nevnt før). Brukt til å få kontroll over NOWAC data
% 2. Pippelinen. Standardi for NOWAC analyser.
% 3. n=1, RNA-seq, ... og andre per-prosjekt-pipelines. Brukt for diverse
% prosjekter.
% 4. MIxT
% 5. Kvik Pathways, ... og andre små visualiseringer
% 6. Bidrag til forskjellige andre paper (den nature methods saken, etc)
% ...Combined ....

We have used the \gls{x} to implement both batch processing systems targeted at
high-throughput analysis pipelines, as well as interactive data
exploration systems for interactively exploring the results and emerging
patterns from these analyses.  We discuss the different systems and areas we
have implemented. 

Combined these demonstrate how the X approach has been used for a full

\section{Summary of Results} 



\section{List of papers} 
This section contains a list of papers along with short descriptions and my
personal contribution to each paper. 
\capstartfalse
\begin{table}[H]
    \centering
    \begin{tabular}{ | l | p{9.5cm} | }
    \hline
         Title & Kvik: three-tier data exploration tools for flexible analysis
         of genomic data in epidemiological studies \\ \hline
         
         Authors & \textbf{Bjørn Fjukstad}, Karina Standahl Olsen, Mie Jareid,
         Eiliv Lund, and Lars Ailo Bongo \\ \hline
         
         Description & The initial description of Kvik, and how we used it to
         implement Kvik Pathways, a web application for browsing biologicap
         pathway maps integrated with gene expression data from the \gls{nowac}
         cohort. 
         \\ \hline
         
         Contribution & Designed, implemented, and deployed Kvik and Kvik
         Pathways. Evaluated the system and wrote the manuscript. \\ \hline
         
         Publication date & 15 March 2015 \\ \hline 

         Publication venue & F1000 \\ \hline
         
         Citation & \cite{fjukstad2015kvik} \bibentry{fjukstad2015kvik} \\
         \hline 
    \end{tabular}
    \label{p1}

\end{table}
% \hfill 
\begin{table}[H]

    \begin{tabular}{ | l | p{9.5cm} | }
    \hline
         Title & Building Applications For Interactive Data Exploration In
         Systems Biology. \\ \hline
         
         Authors & \textbf{Bjørn Fjukstad}, Vanessa Dumeaux, Karina
         Standahl Olsen, Michael Hallett, Eiliv Lund, and Lars Ailo Bongo.  \\
         \hline
         
         Description & Describes how we further developed the ideas from Paper 1
         into an approach that we used to build the \gls{mixt} web application. 
         \\ \hline
         
         Contribution & 
         Designed, implemented, and deployed Kvik and the \gls{mixt} web
         application.  Evaluated the system and wrote the manuscript. 
         \\ \hline
         
         Publication date & 20 August 2017. \\ \hline  

         Publication venue & The 8th ACM Conference on Bioinformatics,
         Computational Biology, and Health Informatics (ACM BCB) August 20–23,
         2017.  \\
         \hline
         
         Citation & \cite{fjukstad2017building} \bibentry{fjukstad2017building}
         \\ \hline 
    \end{tabular}
    \label{p2}
    
\end{table}
% \hfill 
\begin{table}[H]
    
    \centering
    \begin{tabular}{ | l | p{9.5cm} | }
    \hline
         Title & Interactions Between the Tumor and the Blood Systemic Response
         of Breast Cancer Patients \\ \hline
         
         Authors & Vanessa Dumeaux, \textbf{Bjørn Fjukstad}, Hans E Fjosne,
         Jan-Ole Frantzen, Marit Muri Holmen, Enno Rodegerdts, Ellen
         Schlichting, Anne-Lise Børresen-Dale, Lars Ailo Bongo, Eiliv Lund,
         Michael Hallett.  \\ \hline
         
         Description & Describes the \gls{mixt} system which enables
         identification of genes and pathways in the primary tumor that are
         tightly
         linked to genes and pathways in the patient \gls{sr}. 
         \\ \hline
         
         Contribution & 
         Designed, implemented, and deployed the \gls{mixt} web application.
        Contributed to write the manuscript. 
         \\ \hline
         
         Publication date & 28 September 2017. \\ \hline  

         Publication venue &  PLoS Computational Biology \\ \hline
         
         Citation & \cite{dumeaux2017interactions}
         \bibentry{dumeaux2017interactions}
         \\ \hline 
    \end{tabular}
    \label{p3}
    
    \hfill 

    \begin{tabular}{ | l | p{9.5cm} | }
    \hline
         Title & A Review of Scalable Bioinformatics Pipelines \\ \hline
         
         Authors & \textbf{Bjørn Fjukstad}, Lars Ailo Bongo. \\ \hline
         
         Description & This review survey several scalable bioinformatics
         pipelines and compare their design and their use of underlying
         frameworks and infrastructures.      \\ \hline
         
         Contribution & 
         Wrote the manuscript.  \\ \hline
         
         Publication date & 23 October 2017 \\ \hline  

         Publication venue & Data Science and Engineering 2017. \\ \hline
         
         Citation & \cite{fjukstad2017review} \bibentry{fjukstad2017review} \\
         \hline 
    \end{tabular}
    \label{p4}
\end{table}
\begin{table}[H]
    \centering
    \begin{tabular}{ | l | p{9.5cm} | }
    \hline
         Title & nsroot: Minimalist Process Isolation Tool Implemented With
         Linux Namespaces.  \\ \hline
         
         Authors & Inge Alexander Raknes, \textbf{Bjørn Fjukstad}, Lars Ailo
         Bongo. \\ \hline
         
         Description & Describes a tool for process isolation built using Linux
         namespaces.          \\ \hline
         
         Contribution & Contributed to the
         manuscript, specifically to the literature review and related works.
         \\ \hline
         
         Publication date & 26 November 2017 \\ \hline  

         Publication venue & Norsk Informatikkonferanse 2017. \\ \hline
         
         Citation & \cite{fjukstad2017review} \bibentry{fjukstad2017review} \\
         \hline 
    \end{tabular}
    \label{p5}
\end{table}
\begin{table}[H]
    \centering
    \begin{tabular}{ | l | p{9.5cm} | }
    \hline
         Title & Transcription factor PAX6 as a novel prognostic factor and
         putative tumour suppressor in non-small cell lung cancer \\ \hline
         
         Authors & Yury Kiselev, Sigve Andersen, Charles Johannessen, 
         \textbf{Bjørn Fjukstad}, Karina Standahl Olsen, Helge Stenvold, Samer
         Al-Saad, Tom Dønnem, Elin Richardsen, Roy M Bremnes, and Lill-Tove
         Rasmussen Busund.\\ \hline
         
         Description & This paper explores the possibility of using the PAX6
         transcription factor as a prognostic marker in non-small cell lung
         cancer. 
         \\ \hline
         
         Contribution & Did the analyses to explore association between PAX6
         gene expression and PAX6 target genes. 
         \\ \hline
         
         Publication date & 22 March 2018 \\ \hline  

         Publication venue & Scientific Reports 2018. \\ \hline
         
         Citation & \cite{kiselev2018transcription}
         \bibentry{kiselev2018transcription} \\
         \hline 
    \end{tabular}
    \label{p6}
\end{table}


\begin{table}[H]

    \centering
    \begin{tabular}{ | l | p{9.5cm} | }
    \hline
         Title & Reproducible Data Analysis Pipelines in Precision Medicine \\
         \hline
         
         Authors &  \textbf{Bjørn Fjukstad}, Vanessa Dumeaux, Michael Hallett,
         Lars Ailo Bongo\\ \hline
         
         Description & This paper outlines how we used the container centric
         development model to build walrus. 
         \\ \hline
         
         Contribution & Design, implementation and evaluation of walrus. Wrote
         the manuscript. 
         \\ \hline
         
         Publication date & TBA \\ \hline  

         Publication venue & TBA \\ \hline
         
         Citation & \cite{walrus} \bibentry{walrus} \\
         \hline 
    \end{tabular}
    \label{p6}
\end{table}

% Husk historien: Fra rå data gjennom komplekse analyse pipeliner og helt til
% forskere kan svømme rundt i resultatene. 

\section{Dissertation Plan} 
This thesis is organized as follows. Chapter 2 describes the characteristics of
state-of-the-art biological datasets, the analysis required to extract knowledge
from these, and the available tools and analysis frameworks. Chapter 3 describes
in detail how we use a container centric development model to build a tool,
walrus, to develop and execute deep analysis pipelines. In Chapter 4 we describe
how we used the same model to develop applications to interactively explore
results from statistical analyses.  Finally, Chapter 5 concludes the work and
discusses future directions. 

